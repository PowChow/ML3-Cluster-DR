{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Author: Ron Weiss <ronweiss@gmail.com>, Gael Varoquaux\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# $Id$\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals.six.moves import xrange\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "#replaced with online news popularity dataset\n",
    "original = pd.read_csv('A3_OnlineNewPopularity_sharegrps_labeled.csv')\n",
    "us_file = original.drop(labels=[' timedelta','url', 'shares_2', 'shares_3', 'shares_5', 'shares_log'], axis=1)\n",
    "#target = np.array(original['shares_2'])\n",
    "news_data = np.array(us_file)\n",
    "X = news_data\n",
    "#us_file.isnull().sum()\n",
    "\n",
    "### SET THE LABELS FROM CLUSTERING\n",
    "n_clusters = 4\n",
    "\n",
    "##############################################################################\n",
    "# Compute clustering with Means\n",
    "\n",
    "k_means = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "t0 = time.time()\n",
    "k_means.fit(X)\n",
    "t_batch = time.time() - t0\n",
    "k_means_labels = k_means.labels_\n",
    "k_means_cluster_centers = k_means.cluster_centers_\n",
    "k_means_labels_unique = np.unique(k_means_labels)\n",
    "\n",
    "y= k_means_labels\n",
    "target = y\n",
    "print k_means_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Break up the dataset into non-overlapping training (75%) and testing\n",
    "# (25%) sets.\n",
    "skf = StratifiedKFold(target, n_folds=4)\n",
    "# Only take the first fold.\n",
    "train_index, test_index = next(iter(skf))\n",
    "\n",
    "\n",
    "X_train = news_data[train_index]\n",
    "y_train = target[train_index]\n",
    "X_test = news_data[test_index]\n",
    "y_test = target[test_index]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "print n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compare GMM outputs content with Kmeans\n",
    "output_class =8\n",
    "g = GMM(n_components=output_class,covariance_type='spherical') #add diagonal?\n",
    "g.fit(news_data)\n",
    "g_label_pred = g.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({6: 7175, 0: 6819, 4: 6773, 7: 5710, 2: 5054, 3: 4804, 1: 3088, 5: 221})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "gmm_freqs = Counter(g_label_pred)\n",
    "print gmm_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 6 0 7]\n",
      "[1 7 3 5 6 0 4 2]\n"
     ]
    }
   ],
   "source": [
    "#output for part #5 of the homework\n",
    "print g_label_pred\n",
    "print pd.unique(g_label_pred)\n",
    "us_file['Target_GMM8'] = g_label_pred\n",
    "us_file.to_csv('News_GMM1_k8.csv', index=False)\n",
    "#us_file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target_GMM8</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.659481</td>\n",
       "      <td>616.854524</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0.975216</td>\n",
       "      <td>0.666763</td>\n",
       "      <td>10.801437</td>\n",
       "      <td>3.078164</td>\n",
       "      <td>4.723127</td>\n",
       "      <td>0.866696</td>\n",
       "      <td>4.582696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093267</td>\n",
       "      <td>0.761153</td>\n",
       "      <td>-0.261078</td>\n",
       "      <td>-0.553498</td>\n",
       "      <td>-0.101069</td>\n",
       "      <td>0.274402</td>\n",
       "      <td>0.062950</td>\n",
       "      <td>0.337218</td>\n",
       "      <td>0.149091</td>\n",
       "      <td>2356.741751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.815415</td>\n",
       "      <td>476.823187</td>\n",
       "      <td>0.562372</td>\n",
       "      <td>0.991256</td>\n",
       "      <td>0.705744</td>\n",
       "      <td>9.191386</td>\n",
       "      <td>3.226360</td>\n",
       "      <td>3.443653</td>\n",
       "      <td>1.354275</td>\n",
       "      <td>4.620080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100233</td>\n",
       "      <td>0.770988</td>\n",
       "      <td>-0.253161</td>\n",
       "      <td>-0.481075</td>\n",
       "      <td>-0.114249</td>\n",
       "      <td>0.283980</td>\n",
       "      <td>0.098237</td>\n",
       "      <td>0.344508</td>\n",
       "      <td>0.165347</td>\n",
       "      <td>2795.454987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.680253</td>\n",
       "      <td>492.457855</td>\n",
       "      <td>0.532695</td>\n",
       "      <td>0.950732</td>\n",
       "      <td>0.665062</td>\n",
       "      <td>10.789869</td>\n",
       "      <td>3.163237</td>\n",
       "      <td>4.677879</td>\n",
       "      <td>1.919865</td>\n",
       "      <td>4.456448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098018</td>\n",
       "      <td>0.736239</td>\n",
       "      <td>-0.266258</td>\n",
       "      <td>-0.515141</td>\n",
       "      <td>-0.112611</td>\n",
       "      <td>0.302156</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.342407</td>\n",
       "      <td>0.166158</td>\n",
       "      <td>3410.662643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.697336</td>\n",
       "      <td>507.300791</td>\n",
       "      <td>0.552194</td>\n",
       "      <td>0.991674</td>\n",
       "      <td>0.696223</td>\n",
       "      <td>10.259575</td>\n",
       "      <td>3.437552</td>\n",
       "      <td>3.770400</td>\n",
       "      <td>0.609284</td>\n",
       "      <td>4.623711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096317</td>\n",
       "      <td>0.760441</td>\n",
       "      <td>-0.247079</td>\n",
       "      <td>-0.479539</td>\n",
       "      <td>-0.109834</td>\n",
       "      <td>0.255876</td>\n",
       "      <td>0.074266</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.138015</td>\n",
       "      <td>2940.644255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.395541</td>\n",
       "      <td>649.644323</td>\n",
       "      <td>0.513805</td>\n",
       "      <td>0.983464</td>\n",
       "      <td>0.667186</td>\n",
       "      <td>11.854422</td>\n",
       "      <td>3.846301</td>\n",
       "      <td>4.861804</td>\n",
       "      <td>0.713864</td>\n",
       "      <td>4.614767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090042</td>\n",
       "      <td>0.780182</td>\n",
       "      <td>-0.250904</td>\n",
       "      <td>-0.535198</td>\n",
       "      <td>-0.097207</td>\n",
       "      <td>0.266592</td>\n",
       "      <td>0.071402</td>\n",
       "      <td>0.342501</td>\n",
       "      <td>0.148378</td>\n",
       "      <td>2589.643880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.547511</td>\n",
       "      <td>425.728507</td>\n",
       "      <td>0.547637</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.682766</td>\n",
       "      <td>7.443439</td>\n",
       "      <td>2.257919</td>\n",
       "      <td>2.266968</td>\n",
       "      <td>2.692308</td>\n",
       "      <td>4.357750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099074</td>\n",
       "      <td>0.707191</td>\n",
       "      <td>-0.249687</td>\n",
       "      <td>-0.481549</td>\n",
       "      <td>-0.112882</td>\n",
       "      <td>0.325397</td>\n",
       "      <td>0.090724</td>\n",
       "      <td>0.325312</td>\n",
       "      <td>0.184474</td>\n",
       "      <td>3162.104072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.634286</td>\n",
       "      <td>564.123763</td>\n",
       "      <td>0.627142</td>\n",
       "      <td>1.126690</td>\n",
       "      <td>0.761829</td>\n",
       "      <td>11.684042</td>\n",
       "      <td>3.249059</td>\n",
       "      <td>5.256028</td>\n",
       "      <td>0.987038</td>\n",
       "      <td>4.622647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097983</td>\n",
       "      <td>0.764879</td>\n",
       "      <td>-0.267368</td>\n",
       "      <td>-0.539305</td>\n",
       "      <td>-0.109718</td>\n",
       "      <td>0.282289</td>\n",
       "      <td>0.065908</td>\n",
       "      <td>0.340840</td>\n",
       "      <td>0.153488</td>\n",
       "      <td>2935.232195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.445884</td>\n",
       "      <td>441.260771</td>\n",
       "      <td>0.530610</td>\n",
       "      <td>0.923292</td>\n",
       "      <td>0.657432</td>\n",
       "      <td>10.481261</td>\n",
       "      <td>3.022242</td>\n",
       "      <td>4.274956</td>\n",
       "      <td>2.507180</td>\n",
       "      <td>4.320950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095529</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>-0.266369</td>\n",
       "      <td>-0.512086</td>\n",
       "      <td>-0.114258</td>\n",
       "      <td>0.312827</td>\n",
       "      <td>0.071082</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.176874</td>\n",
       "      <td>6872.214886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
       "Target_GMM8                                                         \n",
       "0                  10.659481         616.854524          0.516398   \n",
       "1                   9.815415         476.823187          0.562372   \n",
       "2                  10.680253         492.457855          0.532695   \n",
       "3                   9.697336         507.300791          0.552194   \n",
       "4                  10.395541         649.644323          0.513805   \n",
       "5                  10.547511         425.728507          0.547637   \n",
       "6                  10.634286         564.123763          0.627142   \n",
       "7                  10.445884         441.260771          0.530610   \n",
       "\n",
       "              n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
       "Target_GMM8                                                             \n",
       "0                     0.975216                   0.666763   10.801437   \n",
       "1                     0.991256                   0.705744    9.191386   \n",
       "2                     0.950732                   0.665062   10.789869   \n",
       "3                     0.991674                   0.696223   10.259575   \n",
       "4                     0.983464                   0.667186   11.854422   \n",
       "5                     0.936652                   0.682766    7.443439   \n",
       "6                     1.126690                   0.761829   11.684042   \n",
       "7                     0.923292                   0.657432   10.481261   \n",
       "\n",
       "              num_self_hrefs   num_imgs   num_videos   average_token_length  \\\n",
       "Target_GMM8                                                                   \n",
       "0                   3.078164   4.723127     0.866696               4.582696   \n",
       "1                   3.226360   3.443653     1.354275               4.620080   \n",
       "2                   3.163237   4.677879     1.919865               4.456448   \n",
       "3                   3.437552   3.770400     0.609284               4.623711   \n",
       "4                   3.846301   4.861804     0.713864               4.614767   \n",
       "5                   2.257919   2.266968     2.692308               4.357750   \n",
       "6                   3.249059   5.256028     0.987038               4.622647   \n",
       "7                   3.022242   4.274956     2.507180               4.320950   \n",
       "\n",
       "                ...        min_positive_polarity   max_positive_polarity  \\\n",
       "Target_GMM8     ...                                                        \n",
       "0               ...                     0.093267                0.761153   \n",
       "1               ...                     0.100233                0.770988   \n",
       "2               ...                     0.098018                0.736239   \n",
       "3               ...                     0.096317                0.760441   \n",
       "4               ...                     0.090042                0.780182   \n",
       "5               ...                     0.099074                0.707191   \n",
       "6               ...                     0.097983                0.764879   \n",
       "7               ...                     0.095529                0.722596   \n",
       "\n",
       "              avg_negative_polarity   min_negative_polarity  \\\n",
       "Target_GMM8                                                   \n",
       "0                         -0.261078               -0.553498   \n",
       "1                         -0.253161               -0.481075   \n",
       "2                         -0.266258               -0.515141   \n",
       "3                         -0.247079               -0.479539   \n",
       "4                         -0.250904               -0.535198   \n",
       "5                         -0.249687               -0.481549   \n",
       "6                         -0.267368               -0.539305   \n",
       "7                         -0.266369               -0.512086   \n",
       "\n",
       "              max_negative_polarity   title_subjectivity  \\\n",
       "Target_GMM8                                                \n",
       "0                         -0.101069             0.274402   \n",
       "1                         -0.114249             0.283980   \n",
       "2                         -0.112611             0.302156   \n",
       "3                         -0.109834             0.255876   \n",
       "4                         -0.097207             0.266592   \n",
       "5                         -0.112882             0.325397   \n",
       "6                         -0.109718             0.282289   \n",
       "7                         -0.114258             0.312827   \n",
       "\n",
       "              title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "Target_GMM8                                                       \n",
       "0                             0.062950                 0.337218   \n",
       "1                             0.098237                 0.344508   \n",
       "2                             0.071189                 0.342407   \n",
       "3                             0.074266                 0.351404   \n",
       "4                             0.071402                 0.342501   \n",
       "5                             0.090724                 0.325312   \n",
       "6                             0.065908                 0.340840   \n",
       "7                             0.071082                 0.338500   \n",
       "\n",
       "              abs_title_sentiment_polarity       shares  \n",
       "Target_GMM8                                              \n",
       "0                                 0.149091  2356.741751  \n",
       "1                                 0.165347  2795.454987  \n",
       "2                                 0.166158  3410.662643  \n",
       "3                                 0.138015  2940.644255  \n",
       "4                                 0.148378  2589.643880  \n",
       "5                                 0.184474  3162.104072  \n",
       "6                                 0.153488  2935.232195  \n",
       "7                                 0.176874  6872.214886  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_gmm_groupby = us_file.groupby('Target_GMM8').mean()\n",
    "us_gmm_groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_gmm_groupby.to_csv('gmm_groupby_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.000000 spherical Train accuracy: 67.2, converged: True\n",
      "3.000000 spherical Test accuracy: 70.1\n",
      "4.000000 spherical Train accuracy: 10.2, converged: True\n",
      "4.000000 spherical Test accuracy: 7.3\n",
      "5.000000 spherical Train accuracy: 45.7, converged: True\n",
      "5.000000 spherical Test accuracy: 48.3\n",
      "6.000000 spherical Train accuracy: 10.2, converged: True\n",
      "6.000000 spherical Test accuracy: 7.3\n",
      "7.000000 spherical Train accuracy: 67.2, converged: True\n",
      "7.000000 spherical Test accuracy: 70.1\n",
      "8.000000 spherical Train accuracy: 21.9, converged: True\n",
      "8.000000 spherical Test accuracy: 21.9\n",
      "9.000000 spherical Train accuracy: 2.5, converged: True\n",
      "9.000000 spherical Test accuracy: 2.0\n",
      "10.000000 spherical Train accuracy: 21.9, converged: True\n",
      "10.000000 spherical Test accuracy: 21.9\n",
      "3.000000 diag Train accuracy: 36.7, converged: False\n",
      "3.000000 diag Test accuracy: 22.8\n",
      "4.000000 diag Train accuracy: 38.9, converged: False\n",
      "4.000000 diag Test accuracy: 26.9\n",
      "5.000000 diag Train accuracy: 13.6, converged: False\n",
      "5.000000 diag Test accuracy: 34.8\n",
      "6.000000 diag Train accuracy: 25.1, converged: False\n",
      "6.000000 diag Test accuracy: 69.6\n",
      "7.000000 diag Train accuracy: 13.6, converged: False\n",
      "7.000000 diag Test accuracy: 34.8\n",
      "8.000000 diag Train accuracy: 14.4, converged: False\n",
      "8.000000 diag Test accuracy: 24.9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "EM algorithm was never able to compute a valid likelihood given initial parameters. Try different init parameters (or increasing n_init) or check for degenerate data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-bfa93478277f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Train the other parameters using the EM algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/mixture/gmm.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;34m\"EM algorithm was never able to compute a valid likelihood \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;34m\"given initial parameters. Try different init parameters \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \"(or increasing n_init) or check for degenerate data.\")\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;31m# self.n_iter == 0 occurs when using GMM within HMM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: EM algorithm was never able to compute a valid likelihood given initial parameters. Try different init parameters (or increasing n_init) or check for degenerate data."
     ]
    }
   ],
   "source": [
    "# Try GMMs using different types of covariances.\n",
    "classifiers = dict((covar_type, GMM(n_components=n_classes,\n",
    "                    covariance_type=covar_type))\n",
    "                   for covar_type in ['spherical', 'diag'])\n",
    "                   #for covar_type in ['spherical', 'diag', 'tied', 'full'])\n",
    "                                                            \n",
    "#n_classifiers = len(classifiers)\n",
    "class_range = [3,4,5,6,7,8,9,10]\n",
    "\n",
    "#add a changing kemans label too\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    for n_classes in class_range:\n",
    "        # Since we have class labels for the training data, we can\n",
    "        # initialize the GMM parameters in a supervised manner.\n",
    "        classifier.means_ = np.array([X_train[y_train == i].mean(axis=0)\n",
    "                                      for i in xrange(n_classes)])\n",
    "\n",
    "        # Train the other parameters using the EM algorithm.\n",
    "        classifier.fit(X_train)\n",
    "        y_train_pred = classifier.predict(X_train)\n",
    "        train_accuracy = np.mean(y_train_pred.ravel() == y_train.ravel()) * 100\n",
    "        print '%f %s Train accuracy: %.1f, converged: %s' % (n_classes, name, train_accuracy, classifier.converged_)\n",
    "\n",
    "        y_test_pred = classifier.predict(X_test)\n",
    "        test_accuracy = np.mean(y_test_pred.ravel() == y_test.ravel()) * 100\n",
    "        print '%f %s Test accuracy: %.1f' % (n_classes, name, test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.000, 0.96s,  959273160582714,   0.942,   0.961,   0.951,   0.981,   0.942,    0.778,   0.776,   0.770,   0.683,\n",
      "3.000, 4.41s,  596446571502952,   0.576,   0.526,   0.550,   0.372,   0.526,    0.313,   0.258,   0.229,   0.208,\n",
      "4.000, 4.22s,  436139861874352,   0.723,   0.697,   0.710,   0.621,   0.697,    0.453,   0.424,   0.448,   0.152,\n",
      "5.000, 4.86s,  315231323361863,   0.788,   0.615,   0.691,   0.536,   0.615,    0.418,   0.348,   0.368,   0.156,\n",
      "6.000, 7.55s,  249076372081758,   0.757,   0.646,   0.697,   0.562,   0.646,    0.406,   0.310,   0.298,   0.116,\n",
      "7.000, 8.44s,  184871217478282,   0.788,   0.669,   0.724,   0.579,   0.669,    0.410,   0.320,   0.324,   0.134,\n",
      "8.000, 8.48s,  157837088633236,   0.796,   0.699,   0.745,   0.606,   0.699,    0.362,   0.311,   0.319,   0.182,\n",
      "9.000, 10.05s,  134573470393785,   0.812,   0.717,   0.761,   0.618,   0.716,    0.387,   0.309,   0.309,   0.176,\n",
      "10.000, 11.75s,  122591625882848,   0.791,   0.663,   0.722,   0.577,   0.663,    0.428,   0.311,   0.329,   0.206,\n"
     ]
    }
   ],
   "source": [
    "# GMM labels compared with Kmeans labeling\n",
    "# Get values to plot and compare\n",
    "\n",
    "np.random.seed(123)\n",
    "cluster_range = [2,3,4,5,6,7,8,9,10]\n",
    "sample_size = 500\n",
    "\n",
    "for n_clusters in cluster_range: \n",
    "\n",
    "    k_means = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "    t0 = time.time()\n",
    "    k_means.fit(news_data)\n",
    "    t_batch = time.time() - t0\n",
    "    k_means_labels = k_means.labels_\n",
    "    k_means_cluster_centers = k_means.cluster_centers_\n",
    "\n",
    "    g = GMM(n_components=n_clusters,covariance_type='spherical')\n",
    "    g_t0 = time.time()\n",
    "    g.fit(news_data)\n",
    "    g_t_batch = time.time() - g_t0\n",
    "    g_label_pred = g.predict(X)\n",
    "    \n",
    "    \n",
    "    print('%.3f, %.2fs,  %i,   %.3f,   %.3f,   %.3f,   %.3f,   %.3f,    %.3f,   %.3f,   %.3f,   %.3f,'\n",
    "      % (n_clusters,(time.time() - t0), k_means.inertia_,\n",
    "         metrics.homogeneity_score(k_means_labels, g_label_pred),\n",
    "         metrics.completeness_score(k_means_labels, g_label_pred),\n",
    "         metrics.v_measure_score(k_means_labels, g_label_pred),\n",
    "         metrics.adjusted_rand_score(k_means_labels, g_label_pred),\n",
    "         metrics.adjusted_mutual_info_score(k_means_labels,  g_label_pred),\n",
    "         metrics.silhouette_score(news_data, g_label_pred,\n",
    "                                  metric='euclidean',\n",
    "                                  sample_size=sample_size),\n",
    "         metrics.silhouette_score(news_data, g_label_pred,\n",
    "                                  metric='manhattan',\n",
    "                                  sample_size=sample_size),\n",
    "         metrics.silhouette_score(news_data, g_label_pred,\n",
    "                                  metric='cityblock',\n",
    "                                  sample_size=sample_size),\n",
    "         metrics.silhouette_score(news_data, g_label_pred,\n",
    "                                  metric='cosine',\n",
    "                                  sample_size=sample_size)\n",
    "        )\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "# Number of samples per component\n",
    "n_samples = 500\n",
    "\n",
    "# Generate random sample, two components\n",
    "# np.random.seed(0)\n",
    "# C = np.array([[0., -0.1], [1.7, .4]])\n",
    "# X = np.r_[np.dot(np.random.randn(n_samples, 2), C),\n",
    "#           .7 * np.random.randn(n_samples, 2) + np.array([-6, 3])]\n",
    "\n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 60)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        # Fit a mixture of Gaussians with EM\n",
    "        gmm = mixture.GMM(n_components=n_components, covariance_type=cv_type)\n",
    "        gmm.fit(X)\n",
    "        bic.append(gmm.bic(X))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "\n",
    "bic = np.array(bic)\n",
    "color_iter = itertools.cycle(['k', 'r', 'g', 'b', 'c', 'm', 'y'])\n",
    "clf = best_gmm\n",
    "bars = []\n",
    "\n",
    "# Plot the BIC scores\n",
    "spl = plt.subplot(2, 1, 1)\n",
    "for i, (cv_type, color) in enumerate(zip(cv_types, color_iter)):\n",
    "    xpos = np.array(n_components_range) + .2 * (i - 2)\n",
    "    bars.append(plt.bar(xpos, bic[i * len(n_components_range):\n",
    "                                  (i + 1) * len(n_components_range)],\n",
    "                        width=.2, color=color))\n",
    "plt.xticks(n_components_range)\n",
    "plt.ylim([bic.min() * 1.01 - .01 * bic.max(), bic.max()])\n",
    "plt.title('BIC score per model')\n",
    "xpos = np.mod(bic.argmin(), len(n_components_range)) + .65 +\\\n",
    "    .2 * np.floor(bic.argmin() / len(n_components_range))\n",
    "plt.text(xpos, bic.min() * 0.97 + .03 * bic.max(), '*', fontsize=14)\n",
    "spl.set_xlabel('Number of components')\n",
    "spl.legend([b[0] for b in bars], cv_types)\n",
    "\n",
    "# Plot the winner\n",
    "splot = plt.subplot(2, 1, 2)\n",
    "Y_ = clf.predict(X)\n",
    "for i, (mean, covar, color) in enumerate(zip(clf.means_, clf.covars_,\n",
    "                                             color_iter)):\n",
    "    v, w = linalg.eigh(covar)\n",
    "    if not np.any(Y_ == i):\n",
    "        continue\n",
    "    plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color)\n",
    "\n",
    "    # Plot an ellipse to show the Gaussian component\n",
    "    angle = np.arctan2(w[0][1], w[0][0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    v *= 4\n",
    "    ell = mpl.patches.Ellipse(mean, v[0], v[1], 180 + angle, color=color)\n",
    "    ell.set_clip_box(splot.bbox)\n",
    "    ell.set_alpha(.5)\n",
    "    splot.add_artist(ell)\n",
    "\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-3, 6)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Selected GMM: full model, 2 components')\n",
    "plt.subplots_adjust(hspace=.35, bottom=.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_iter = itertools.cycle(['r', 'g', 'b', 'c', 'm'])\n",
    "\n",
    "\n",
    "for i, (clf, title) in enumerate([\n",
    "        (mixture.GMM(n_components=10, covariance_type='full', n_iter=100),\n",
    "         \"Expectation-maximization\")]):\n",
    "\n",
    "    clf.fit(X)\n",
    "    splot = plt.subplot(3, 1, 1 + i)\n",
    "    Y_ = clf.predict(X)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            clf.means_, clf._get_covars(), color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        # as the DP will not use every component it has access to\n",
    "        # unless it needs it, we shouldn't plot the redundant\n",
    "        # components.\n",
    "        if not np.any(Y_ == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180 * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180 + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "\n",
    "    plt.xlim(-6, 4 * np.pi - 6)\n",
    "    plt.ylim(-5, 5)\n",
    "    plt.title(title)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
